<h2>Dodge!: Analysis</h2>
<h3>Small dataset</h3>
<p>
  The following approach solves the Small dataset on a single node. Before we
  start to navigate this sea of monsters, we should figure out how far the
  monsters from each generator advance before (possibly) colliding with other
  monsters. The problem might seem daunting because each generator produces an
  infinite stream of monsters. However, notice that the pattern of collisions
  (if any) repeats. That is, if one monster from generator X collides with
  another monster from generator Y, then the next monster generated by X will
  also collide in the same cell with the next monster generated by Y, and so
  on.
</p><p>
  We make one
  <a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>
  (DP) pass through the traversable area of the game (hereafter the "grid"),
  starting from the target cell in the top right, and going row by row, from
  right to left in each row. For each generator, we keep track of where in its
  row/column its monsters have a collision, if any. In each cell (r, c), if
  the generators for row r and column c are in positions such that their
  monsters could collide, and neither generator has recorded a collision yet,
  we update both generators with the collision position. Our traversal order
  ensures that we always check for possible earlier collisions above and/or to
  the right of our current cell before we declare a collision in that cell.
</p><p>
  Then, we make a second DP pass, this time representing the player's movement
  through the grid. In this case, the state is the total number of monster
  encounters experienced so far, which we want to minimize. As in similar DP
  problems about moving from the lower left corner of a grid to the upper right
  corner, the best value for a cell is determined by the best values of the two
  cells (if any) to the left of and below that cell. Notice that being in cell
  (r, c) implies that we made r + c moves to get there, regardless of the exact
  path we took.
</p><p>
  We run the DP row by row, from left to right in each row, starting from the
  player's starting cell (0, 0). If we want to save memory, we can only keep
  track of our current row and the previous one, but this is not required. In
  each cell, we check for encounters with the monsters from that row and
  column's two generators; first we use our per-generator data from the first
  DP pass to see whether each monster could make it to that cell at all, and
  then, for each monster that could, compare the number of moves we have made
  so far with the distance of that monster's generator from the grid.
</p><p>
  This approach makes two passes through the grid, and uses
  O(<b>N</b><sup>2</sup>) time and O(<b>N</b>) memory. The potentially tricky
  parts are visualizing and implementing the rules of the game correctly (for
  example, not failing to include encounters in the target cell at the end of
  the game) and avoiding off-by-one errors.
</p>
<h3>Large dataset</h3>
<p>
  To extend the above approach to the Large dataset, we need to distribute both
  DP steps, but in a way that ensures that each calculation has all the
  information it needs from previous calculations. We will describe the
  adaptation of the first DP pass from our Small solution, but we can use
  essentially the same strategy for the second DP pass.
</p><p>
  We divide the rows evenly among the 100 nodes; each node will consistently be
  responsible for its subset of rows. We evenly partition the columns into 100
  subsets in the same way. This divides the grid into 10000 blocks; let block
  (x, y) be the block in the x-th subset of rows from the top (the ones handled
  by node x) and the y-th subset of columns from the right. Then we proceed as
  follows:
</p><p>
  Step 1: Node 0 handles block (0, 0) as in the single-node solution above.
  Blocks (0, 1) and (1, 0) need the results (i.e. the per-generator collision
  data) to proceed, so node 0 sends them to itself and to node 1.
</p><p>
  Step 2: Simultaneously, node 0 handles block (0, 1) and node 1 handles block
  (1, 0). They send results to Nodes 0, 1, and 2.
</p><p>
  Step 3: Simultaneously, nodes 0, 1, and 2 handles blocks (0, 2), (1, 1), and
  (2, 0), respectively, and send results to Nodes 0 through 3.
</p><p>
  ...and so on. This takes a total of 2 * 100 + 1 = 201 steps, whereas
  our single-node solution handling one block per step would have needed 10000
  steps. This is enough of a distribution factor to solve the Large dataset. As
  usual, what remains is to ensure that the distribution strategy passes the
  right information, correctly handles grids with <b>N</b> &lt; 100, and so on.
</p>
